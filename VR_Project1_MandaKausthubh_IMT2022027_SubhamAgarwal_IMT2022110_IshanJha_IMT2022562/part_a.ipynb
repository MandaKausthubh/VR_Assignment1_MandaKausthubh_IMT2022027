{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from skimage.feature import hog\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part a\n",
    "_________________________________________________________________________________________________________________________________\n",
    "\n",
    "Models we use: XGBoost and Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = '../dataset' \n",
    "# Input folder that must contain 2 folder, one with masked face images and another non-masked\n",
    "# Here we assume that name of the 2 sub-directories are 'with_mask' and 'without_mask'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each image we create a feature vector that reflects texture, Histogram of Gradients (HoG), Scale-invaiant fetaures, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize all images to a fixed size\n",
    "IMAGE_SIZE = (64, 64)  # Ensures consistent feature vector length\n",
    "\n",
    "def extract_texture_features(image, num_bins=32):\n",
    "    \"\"\"Extracts grayscale histogram-based texture features.\"\"\"\n",
    "    image = cv2.resize(image, IMAGE_SIZE)  # Ensure fixed size\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hist = cv2.calcHist([gray], [0], None, [num_bins], [0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    \"\"\"Extracts HOG features with a fixed-length descriptor.\"\"\"\n",
    "    image = cv2.resize(image, IMAGE_SIZE)  # Ensure fixed size\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    features = hog(\n",
    "        gray, \n",
    "        orientations=9, \n",
    "        pixels_per_cell=(8, 8), \n",
    "        cells_per_block=(2, 2), \n",
    "        block_norm='L2-Hys'\n",
    "    )\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_shape_features(image, num_bins=32):\n",
    "    \"\"\"Extracts edge-based shape features using Canny and histogram.\"\"\"\n",
    "    image = cv2.resize(image, IMAGE_SIZE)  # Ensure fixed size\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    \n",
    "    edge_hist = cv2.calcHist([edges], [0], None, [num_bins], [0, 256])\n",
    "    edge_hist = cv2.normalize(edge_hist, edge_hist).flatten()\n",
    "    return edge_hist\n",
    "\n",
    "def extract_color_features(image):\n",
    "    \"\"\"Extracts color histogram features in the HSV space.\"\"\"\n",
    "    image = cv2.resize(image, IMAGE_SIZE)  # Ensure fixed size\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist\n",
    "\n",
    "def extract_keypoint_features(image, max_features=128):\n",
    "    \"\"\"Extracts ORB keypoint-based features with a fixed length.\"\"\"\n",
    "    image = cv2.resize(image, IMAGE_SIZE)  # Ensure fixed size\n",
    "    orb = cv2.ORB_create()\n",
    "    kp, des = orb.detectAndCompute(image, None)\n",
    "\n",
    "    if des is None:\n",
    "        return np.zeros(max_features)  # No keypoints, return zero vector\n",
    "\n",
    "    des = des.flatten()  # Flatten descriptor array\n",
    "    return des[:max_features] if len(des) >= max_features else np.pad(des, (0, max_features - len(des)))\n",
    "\n",
    "def extract_features(image):\n",
    "    \"\"\"Combines all feature extractions into a single feature vector.\"\"\"\n",
    "    texture_features = extract_texture_features(image)\n",
    "    shape_features = extract_shape_features(image)\n",
    "    color_features = extract_color_features(image)\n",
    "    hog_features = extract_hog_features(image)\n",
    "    keypoint_features = extract_keypoint_features(image)\n",
    "\n",
    "    return np.hstack((texture_features, shape_features, color_features, hog_features, keypoint_features))\n",
    "\n",
    "#image = cv2.imread('dataset/with_mask/0_0_≈˙◊¢ 2020-02-23 132115.png')\n",
    "#image = cv2.resize(image, (128, 128))  \n",
    "#features = extract_features(image)  # Extract handcrafted features\n",
    "#print(f'{type(features)} , {np.shape(features)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 4095 | Train: 3276 | Test: 819\n"
     ]
    }
   ],
   "source": [
    "# Define dataset path\n",
    "DATASET_PATH = input_folder\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]  # these must be name of folders inside DATASET_PATH\n",
    "\n",
    "# Function to load images and extract features\n",
    "def load_dataset():\n",
    "    X, y = [], []\n",
    "\n",
    "    for category in CATEGORIES:\n",
    "        label = 1 if category == \"with_mask\" else 0  # Assign label (1 = mask, 0 = no mask)\n",
    "        folder_path = os.path.join(DATASET_PATH, category)\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "            if image is None:\n",
    "                continue  # Skip unreadable images\n",
    "\n",
    "            image = cv2.resize(image, (128, 128))  # Resize for consistency\n",
    "            features = extract_features(image)  # Extract handcrafted features\n",
    "\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_dataset()\n",
    "\n",
    "X, y = shuffle(X, y, random_state=42)  # Ensures random order but reproducibility\n",
    "# Split into training & testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print dataset info\n",
    "print(f\"Total samples: {len(X)} | Train: {len(X_train)} | Test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train an ensumble model, precisely XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test Accuracy: 0.9414\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split of data already done\n",
    "# Convertng to DMatrix (XGBoost’s optimized data structure)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",  # Binary classification\n",
    "    \"eval_metric\": \"logloss\",        # Log loss as evaluation metric\n",
    "    \"eta\": 0.1,                       # Learning rate\n",
    "    \"max_depth\": 10,                    # Tree depth\n",
    "    \"subsample\": 0.8,                  # Use 80% of data per tree\n",
    "    \"colsample_bytree\": 0.8,           # Use 80% of features per tree\n",
    "    \"seed\": 42                         # Reproducibility\n",
    "}\n",
    "\n",
    "# Training the  model\n",
    "num_rounds = 200  # number of boosting rounds\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "\n",
    "# predictions on test split\n",
    "y_pred_prob = bst.predict(dtest)\n",
    "\n",
    "# Converting probabilities to binary labels (0 or 1)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train and test on a Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinesh14/CourseWork/VR_P1/env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Accuracy (k=5): 0.8971\n",
      "Epoch 1/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6773 - loss: 0.9061\n",
      "Epoch 2/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8489 - loss: 0.4527\n",
      "Epoch 3/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8788 - loss: 0.3358\n",
      "Epoch 4/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2817\n",
      "Epoch 5/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2864\n",
      "Epoch 6/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2128\n",
      "Epoch 7/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2105\n",
      "Epoch 8/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.1836\n",
      "Epoch 9/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.1592\n",
      "Epoch 10/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.1440\n",
      "Epoch 11/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1226\n",
      "Epoch 12/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1061\n",
      "Epoch 13/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1124\n",
      "Epoch 14/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.1041\n",
      "Epoch 15/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9569 - loss: 0.0946\n",
      "Epoch 16/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9609 - loss: 0.0890\n",
      "Epoch 17/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.0989\n",
      "Epoch 18/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.0801\n",
      "Epoch 19/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9648 - loss: 0.0753\n",
      "Epoch 20/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0626\n",
      "Epoch 21/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 0.0663\n",
      "Epoch 22/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9593 - loss: 0.0873\n",
      "Epoch 23/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9652 - loss: 0.0737\n",
      "Epoch 24/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.0673\n",
      "Epoch 25/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.0734\n",
      "Epoch 26/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0697\n",
      "Epoch 27/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.0658\n",
      "Epoch 28/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0604\n",
      "Epoch 29/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.0479\n",
      "Epoch 30/30\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.0659\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9190 - loss: 0.3017 \n",
      "Test Accuracy: 0.9145\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Splitting data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer\n",
    "        Dropout(0.3),  # Dropout for regularization\n",
    "        Dense(128, activation='relu'),  # Hidden layer\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),  # Hidden layer\n",
    "        Dense(1, activation='sigmoid')  # Output layer (Binary Classification)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# k-Fold Cross Validation\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "validation_accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Create a new model for each fold\n",
    "    model = create_model()\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=30, batch_size=32, verbose=0, validation_data=(X_val_fold, y_val_fold))\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    validation_accuracies.append(val_accuracy)\n",
    "\n",
    "# Average validation accuracy across folds\n",
    "avg_val_accuracy = np.mean(validation_accuracies)\n",
    "print(f\"Average Validation Accuracy (k={k}): {avg_val_accuracy:.4f}\")\n",
    "\n",
    "# Training final model on the full training data\n",
    "final_model = create_model()\n",
    "final_model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = final_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
